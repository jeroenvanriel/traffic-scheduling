#+options: ':t *:t -:t ::t <:t H:1 \n:nil ^:t arch:headline author:t
#+options: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+options: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+options: tasks:t tex:t timestamp:t title:t toc:nil todo:t |:t
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+startup: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [bigger]
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage[export]{adjustbox}
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 28.1 (Org mode 9.7)
#+cite_export: natbib
#+bibliography: references.bib
#+title: Learning to Schedule
#+date: November 2023
#+author: Jeroen van Riel
#+email: jeroenvanriel@outlook.com

* Combinatorial Optimization

** knapsack (example)
- finite set of items
- item $i$ has non-negative weight $w_i$ and value $v_i$
- choose items to maximize total value while keeping total weight at most $c$

- as a MILP

\begin{equation}
\begin{align}
    \text{max} \; & vx \\
    \text{s.t.} \; & wx \leq c \\
                    & x \geq 0 \\
                    & x \in \mathbb{Z}
\end{align}
\end{equation}

* Learning problem
- set of problem instances $\mathcal{I}$
- distribution $P$ over instances
- set of algorithms $\mathcal{A}$
- measure of optimality $m : \mathcal{I} \times \mathcal{A} \rightarrow \mathbb{R}$

* Learning problem
- general learning objective
\begin{align}
\max_{a \in \mathcal{A}} \mathbb{E}_{i \sim P} \; m(i, a)
\end{align}

- no access to $P$, so use samples
\begin{align}
\max_{a \in \mathcal{A}} \sum_{i \in D_{\mathit{train}}} \frac{1}{|D_\mathit{train}|} m(i, a)
\end{align}

* Learning problem

- examples of algorithm spaces $\mathcal{A}$
  - all possible C++ programs
  - finite set of knapsack heuristics
  - algorithm parameterized by neural network with weights $\theta \in
    \mathbb{R}^p$
\begin{align}
\max_{\theta \in R^p} \mathbb{E}_{i \sim P} m(i, a(\theta))
\end{align}

* Motivations for ML in CO [cite:@bengioMachineLearningCombinatorial2020]

- fast approximations
  - derived in generic way
- learning from demonstration
  - imitation learning
  - expert such as MILP solver

\vfill
\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{figures/Bengio-imitation-learning.png}
\end{figure}

* Motivations for ML in CO [cite:@bengioMachineLearningCombinatorial2020]

- better algorithms
  - by systematically exploring $\mathcal{A}$
  - by exploiting instance distribution
- learning from experience
  - objective encoded in rewards
  - algorithms (examples)
    - search-based and branch & bound
    - genetic algorithms
    - reinforcement learning

\vfill
\begin{figure}
  \centering
  \includegraphics[width=0.75\textwidth]{figures/Bengio-reinforcement-learning.png}
\end{figure}


* Job shop (= $\mathcal{I}$)

- $m$ machines
- $n$ jobs
- fixed machine order for each job

\vfill
(closely related to the traffic scheduling variant)

* Job shop (= $\mathcal{I}$)
- example schedule

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/job-shop-schedule.pdf}
\end{figure}

* Job shop (= $\mathcal{I}$)

- job $j$ on machine $i$ is operation $(i,j)$
- operations $N$
- order of operations for particular job $j$ is fixed
  \begin{align*}
  (i,j) \rightarrow (k,j) \in \mathcal{C}
  \end{align*}
- order among jobs $j$ and $l$ is optimization decision
  \begin{align*}
  (i,j) \rightarrow (i,l) \quad \text{ or } \quad (i,l) \rightarrow (i,j)
  \end{align*}

* Job shop MILP

- makespan objective
- mixed-integer linear program

#+begin_export latex
\scalebox{0.85}{\parbox{.9\linewidth}{
\begin{align*}
\text{minimize } & C_{\text{max}} \\
y_{ij} + p_{ij} &\leq y_{kj}  & \text{ for all } (i,j) \xrightarrow{} (k,j) \in \mathcal{C} \\
y_{il} + p_{il} &\leq  y_{ij} \text{ or } y_{ij} + p_{ij} \leq y_{il}  & \text{ for all } (i,l) \text{ and } (i,j), i =1, \dots,m \\
y_{ij} + p_{ij} &\leq C_{\text{max}} & \text{ for all } (i,j) \in N \\
y_{ij} &\geq 0 & \text{ for all } (i,j) \in N
\end{align*}
}}
#+end_export

* Disjunctive graph

- directed graph $G=(N, \mathcal{C}, \mathcal{D})$
- conjunctive arcs
- disjunctive arcs

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{figures/disjunctive-graph.pdf}
\end{figure}

* Dispatching rule

- widely used in practice
- order jobs and put in schedule one by one
- examples
  - SPT/LPT
  - MWR/LWR

* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-0.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-0.pdf}
    }
\end{figure}
* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-1.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-1.pdf}
    }
\end{figure}
* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-2.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-2.pdf}
    }
\end{figure}
* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-3.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-3.pdf}
    }
\end{figure}
* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-4.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-4.pdf}
    }
\end{figure}

* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-5.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-5.pdf}
    }
\end{figure}

* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-6.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-6.pdf}
    }
\end{figure}
* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-7.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-7.pdf}
    }
\end{figure}
* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-8.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-8.pdf}
    }
\end{figure}
* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-9.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-9.pdf}
    }
\end{figure}

* Dispatching rule (example)

\begin{figure}
    \includegraphics[height=4cm]{figures/dispatch-example/disjunctive-graph/disjunctive-graph-final.pdf}
    \adjustbox{margin=1cm 0 0 .5cm}{
        \includegraphics[height=2.3cm,left]{figures/dispatch-example/schedule/job-shop-schedule-9.pdf}
    }
\end{figure}

* Placement rule

- dispatching rule is not sufficient
- the example applied /last position rule/
- alternatively use /earliest gap rule/

\vfill
\begin{figure}
    \includegraphics{figures/job-shop-earliest-gap-1.pdf}
    \includegraphics{figures/job-shop-earliest-gap-2.pdf}
\end{figure}


* Zhang et al.
``Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning''
\vfill

- job shop
- learn dispatching rule
- GNN on disjunctive graph
- remarkable placement rule

* Notation

- operation $O_{jk}$ for /k/'th operation of job $j$
- example
  - $O_{11} = (1, 1)$
  - $O_{12} = (2, 1)$
  - $O_{21} = (2, 2)$

\vfill
\begin{figure}
    \includegraphics{figures/job-shop-earliest-gap-2.pdf}
\end{figure}

* State transition

\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{figures/Zhang-disjunctive-graph.png}
\end{figure}

* State transition

\begin{figure}
  \centering
  \includegraphics[height=4cm]{figures/Zhang-disjunctive-graph-s4.png}
  \adjustbox{margin=1cm 0 0 .5cm}{
    \includegraphics[height=2cm,left]{figures/zhang-schedule-0.pdf}
  }
\end{figure}

* State transition

\begin{figure}
  \centering
  \includegraphics[height=4cm]{figures/Zhang-disjunctive-graph-s5.png}
  \adjustbox{margin=1cm 0 0 .5cm}{
    \includegraphics[height=2cm,left]{figures/zhang-schedule-1.pdf}
  }
\end{figure}

* State transition

\begin{figure}
  \adjustbox{margin=1cm 0 0 0}{
    \includegraphics[height=2cm,left]{figures/zhang-schedule-1.pdf}
  }
  \adjustbox{margin=1cm 0 0 0}{
    \includegraphics[height=2cm,left]{figures/zhang-schedule-2.pdf}
  }
\end{figure}

* Schedule classes [cite:@pinedoSchedulingTheoryAlgorithms2016]

\textbf{Non-delay Schedule}
A feasible schedule is called non-delay if no machine is kept idle while an operation is waiting for processing.

\textbf{Active Schedule}. A feasible non-preemptive schedule is called active if
it is not possible to construct another schedule, through changes in the order
of processing on the machines, with at least one operation finishing earlier and
no operation finishing later.

\vspace{1em}

\textbf{Semi-Active Schedule}. A feasible non-preemptive schedule is called
semi-active if no operation can be completed earlier without changing the order
of processing on any one of the machines.

* Schedule classes [cite:@pinedoSchedulingTheoryAlgorithms2016]

\textbf{Proposition}. Scheduling problem $Jm || \gamma$ has optimal active schedule if $\gamma$ is regular, i.e., non-decreasing function of completion times $C_i$.

\vfill

\begin{figure}
\includegraphics[height=4cm]{figures/schedule_classes.png}
\end{figure}

* Relation to disjunctive graph

\textbf{Proposition} \\
Every complete disjunctive graph corresponds to a unique semi-active schedule.

\vfill

\textbf{Proposition} \\
For every feasible semi-active schedule, there exists a sequence $\chi$ that generates it using the last position rule.


* Tassel et al.

``A Reinforcement Learning Environment For Job-Shop Scheduling''
\vfill

- job shop
- learn something similar to dispatching rule
- actions space subset of $\{ J_0, \dots, J_n, \text{No-Op} \}$

* Tassel et al.

\begin{figure}
    \includegraphics[height=4cm]{figures/Tassel-state.png}
\end{figure}

* Traffic scheduling problem
- total completion time $\sum C_j$
- release dates $r_j$
- chains $j_1 \rightarrow j_2 \rightarrow \dots \rightarrow j_k$
- setup times (switch-over) $s_{ij}$

* Next steps

- relate actions in Tassel et al. to disjunctive graph
- argue that traffic scheduling problem has semi-active optimal schedule
- implement /gym/ environment for traffic scheduling problem

* References
  \begingroup
  \renewcommand{\section}[2]{}
  \bibliography{references}
  \bibliographystyle{plainnat}
  \endgroup

  $\;$
