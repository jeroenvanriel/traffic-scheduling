\documentclass{article}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{datetime}
\usepackage{outlines}

\newdateformat{monthyeardate}{\monthname[\THEMONTH] \THEYEAR}

\newcommand{\newmarkedtheorem}[1]{%
  \newenvironment{#1}
    {\pushQED{\qed}\csname inner@#1\endcsname}
    {\popQED\csname endinner@#1\endcsname}%
  \newtheorem{inner@#1}%
}

\theoremstyle{definition}
%\newtheorem{eg}{Example}[section]
\newmarkedtheorem{eg}{Example}[section]
\newtheorem{observation}{Observation}[section]
\newtheorem{define}{Definition}[section]
\theoremstyle{plain}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{assump}{Assumption}[section]
\newtheorem{remark}{Remark}[section]

\title{Research Plan}
\author{Jeroen van Riel}
\date{\monthyeardate\today}

\begin{document}

\maketitle

\section{Planning}

The main feedback I received from Marko and Rik on my bachelor end project was
that I could have focused a bit better on a narrower selection of topics.
Therefore, in light of the discussion we had about the online problem setting,
my preference would be to first study the offline case (assuming infinite
look-ahead $t_{a} = \infty$) a bit more.

\subsection{Offline Scheduling}

I would like to start with investigating the generalization capabilities of a
reinforcement learning based method for the offline scheduling problem, starting
with the single intersection case.

At this moment, the method of Zhang et al. seems the most promising candidate
here, because I stumbled upon some work in which something very similar is done.
For at least two weeks, I have had a note lying on my desk with the idea to look
into the forks of GitHub repository containing the code of
\cite{zhangLearningDispatchJob2020}. It turns out that one of these forks
belongs to Rob Claassen, which graduated at TU/e on the application of precisely
this deep reinforcement learning method for scheduling
\cite{claassenApplicationDeepReinforcement2022}. The below list outlines my
rough idea of what this part of the project could look like.

\begin{outline}
\1 adapt Zhang et al. \cite{zhangLearningDispatchJob2020} method
    \2 run the code as-is (bare minimal, but done)
    \2 understand and their code (document this for myself)
    \2 understand the graph neural network embedding (GIN)
    \2 show how to adapt the disjunctive graph for our problem
    \2 implement this adaptation

\1 adapt Tassel et al. \cite{tasselReinforcementLearningEnvironment2021} method (optionally)
    \2 explain that this is also some form of dispatching

\1 assess learning ability

    \2 manually define problem instance distribution with some kind of structure
      \3 small platoons
      \3 large platoons
      \3 rate for each lane

      \2 using experiments, study whether the method learns to perform better on
      this class of problems after learning \3 extreme experiment (sanity
      check): just keep using the same instance and see whether the solution
      quality improves

    \2 study learning rate

    \2 study generalization
      \3 accross problem distributions (transfer)
      \3 accross problem sizes
\end{outline}

Once we have gathered hands-on experience with the above approach, a possible
next step would be to try and improve the method by considering alternative
algorithm designs. As we have argued before, the above approach is based on
dispatching. A natural question is whether it makes sense to change this
schedule construction. Furthermore, the above method does not have any
\textit{search} mechanism.
\begin{outline}
\1 systematic study of solution methods
    \2 schedule construction/search, (dispatching rule vs. branch-and-bound)
    \2 platoon preservation theorem
      \3 finish the proof of the current version
      \3 compare this version to the version of Limpens and try to understand why their proof seemed complicated at first sight

    \2 motivate study of heuristics
      \3 manually trying to design heuristics can provide guidance in the design of the schedule construction mechanism, i.e., in how the \textit{search tree is constructed}
      \3 even more, it could potentially provide simple rules for \textit{pruning the search tree}
      \3 relate to Monte Carlo tree search
\end{outline}


\subsection{General Traffic Control}

As we discussed during our last meeting, dropping the assumption of knowing all
future vehicle arrivals, so assuming $t_{a} < \infty$, opens up a lot of
interesting research directions. A good first step here would be to precisely
formulate the general problem we are trying to solve, to which
Section~\ref{sec:general} was meant to be a first attempt.

At this moment, I think that we can extend the method of Zhang et al. towards an
online setting, while also making the regularity assumption (see Definition 3.1
in \cite{timmermanPlatoonFormingAlgorithms2021}) to allow the two-stage
decomposition. When a new vehicle arrives, this means that the scheduler can
only ``insert'' this vehicle somewhere in the existing schedule. A natural first
step is to compare the performance of such policy based on the Zhang et al.
method to the exhaustive (Algorithm 1) and gated (Algorithm 2) policies as
defined by Marko and Rik \cite{timmermanPlatoonFormingAlgorithms2021}.

\subsection{Preliminaries}

Although the research plan is not yet fully specified, there are some aspects that will probably find their way into the project. The topics listed below require a brief introduction in the final report.
\begin{outline}
\1 job shop
    \2 variations
    \2 complexity
    \2 disjunctive graph
    \2 classic methods
        \3 dispatching rules
        \3 branch-and-bound
\1 mixed-integer linear programming
    \2 branch-and-bound
    \2 branch-and-cut
\1 learning objective \cite{bengioMachineLearningCombinatorial2020}
    \2 exploit problem distribution
    \2 generalization
\1 reinforcement learning
    \2 state, transition function, actions, policy, reward
    \2 value-based methods and policy gradient methods
    \2 function approximation
        \3 neural methosd in general (DRL)
        \3 attention-based mechanisms
        \3 graph neural nets
\end{outline}


\subsection{Weekly Schedule}

\textit{todo, some table here}

\bibliography{references}
\bibliographystyle{ieeetr}


\end{document}
