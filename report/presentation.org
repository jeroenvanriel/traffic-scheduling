#+options: ':t *:t -:t ::t <:t H:1 \n:nil ^:t arch:headline author:t
#+options: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+options: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+options: tasks:t tex:t timestamp:t title:t toc:nil todo:t |:t
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+startup: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [bigger]
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage[export]{adjustbox}
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 28.1 (Org mode 9.7)
#+cite_export: natbib
#+bibliography: references.bib
#+title: Learning to Schedule
#+date: November 2023
#+author: Jeroen van Riel
#+email: jeroenvanriel@outlook.com

* Learning problem
- set of problem instances $\mathcal{I}$
- distribution $P$ over instances
- set of algorithms $\mathcal{A}$
- measure of optimality $m : \mathcal{I} \times \mathcal{A} \rightarrow \mathbb{R}$

* Learning problem
- general learning objective
\begin{align}
\min_{a \in \mathcal{A}} \mathbb{E}_{i \sim P} \; m(i, a)
\end{align}

- no access to $\mathcal{I}$ or $P$, so use samples
\begin{align}
\min_{a \in \mathcal{A}} \sum_{i \in D_{\mathit{train}}} \frac{1}{|D_\mathit{train}|} m(i, a)
\end{align}

* Learning problem

- examples of algorithm spaces $\mathcal{A}$
  - all possible C++ programs
  - finite set of knapsack heuristics
  - algorithm parameterized by neural network with weights $\theta \in
    \mathbb{R}^p$
\begin{align}
\min_{\theta \in R^p} \mathbb{E}_{i \sim P} m(i, a(\theta))
\end{align}

* Motivations for ML in CO [cite:@bengioMachineLearningCombinatorial2020]
- fast approximations
  - derived in generic way
- better algorithms
  - by systematically exploring $\mathcal{A}$
  - by exploiting instance distribution

\vfill
- both problems stated in MDP framework
  - environment is \textbf{internal state of algorithm}

* Main learning settings
- learning from demonstration $\rightarrow$ fast approximations
  - imitation learning
  - expert such as MILP solver

\vfill
\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{figures/Bengio-imitation-learning.png}
\end{figure}

* Main learning settings
- learning from experience $\rightarrow$ better algorithms
  - objective encoded in rewards
  - algorithms (examples)
    - search-based and branch & bound
    - genetic algorithms
    - reinforcement learning

\vfill
\begin{figure}
  \centering
  \includegraphics[width=0.75\textwidth]{figures/Bengio-reinforcement-learning.png}
\end{figure}

* Job shop (= $\mathcal{I}$)

- $m$ machines
- $n$ jobs
- fixed machine order for each job

\vfill
(closely related to the traffic scheduling variant)

* Job shop (= $\mathcal{I}$)
- example schedule

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figures/job-shop-schedule.pdf}
\end{figure}

* Job shop (= $\mathcal{I}$)

- job $j$ on machine $i$ is operation $(i,j)$
- operations $N$
- order of operations for particular job $j$ is fixed
  \begin{align*}
  (i,j) \rightarrow (k,j) \in \mathcal{C}
  \end{align*}
- order among jobs $j$ and $l$ is optimization decision
  \begin{align*}
  (i,j) \rightarrow (k,l) \quad \text{ or } \quad (i,l) \rightarrow (k,j)
  \end{align*}

* Job shop MILP

- makespan objective
- mixed-integer linear program

#+begin_export latex
\scalebox{0.85}{\parbox{.9\linewidth}{
\begin{align*}
\text{minimize } & C_{\text{max}} \\
y_{ij} + p_{ij} &\leq y_{kj}  & \text{ for all } (i,j) \xrightarrow{} (k,j) \in \mathcal{C} \\
y_{il} + p_{il} &\leq  y_{ij} \text{ or } y_{ij} + p_{ij} \leq y_{il}  & \text{ for all } (i,l) \text{ and } (i,j), i =1, \dots,m \\
y_{ij} + p_{ij} &\leq C_{\text{max}} & \text{ for all } (i,j) \in N \\
y_{ij} &\geq 0 & \text{ for all } (i,j) \in N
\end{align*}
}}
#+end_export

* Disjunctive graph

- directed graph $G=(N, \mathcal{C}, \mathcal{D})$
- conjunctive arcs
- disjunctive arcs

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{figures/disjunctive-graph.pdf}
\end{figure}

* Dispatching rule

- widely used in practice
- examples
  - SPT/LPT
  - MWR/LWR

* Zhang et al.

- job shop
- learn dispatching rule
- GNN on disjunctive graph
  - removing-arc or adding-arc strategy

* Zhang et al.

\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{figures/Zhang-disjunctive-graph.png}
\end{figure}

* Zhang et al.

\begin{figure}
  \centering
  \includegraphics[height=4cm]{figures/Zhang-disjunctive-graph-s4.png}
  \adjustbox{margin=1cm 0 0 .5cm}{
    \includegraphics[height=2cm,left]{figures/zhang-schedule-0.pdf}
  }
\end{figure}

* Zhang et al.

\begin{figure}
  \centering
  \includegraphics[height=4cm]{figures/Zhang-disjunctive-graph-s5.png}
  \adjustbox{margin=1cm 0 0 .5cm}{
    \includegraphics[height=2cm,left]{figures/zhang-schedule-1.pdf}
  }
\end{figure}

* Zhang et al.

\begin{figure}
  \adjustbox{margin=1cm 0 0 0}{
    \includegraphics[height=2cm,left]{figures/zhang-schedule-1.pdf}
  }
  \adjustbox{margin=1cm 0 0 0}{
    \includegraphics[height=2cm,left]{figures/zhang-schedule-2.pdf}
  }
\end{figure}

* Schdule classes

\textbf{Active Schedule}. A feasible non-preemptive schedule is called active if
it is not possible to construct another schedule, through changes in the order
of processing on the machines, with at least one operation finishing earlier and
no operation finishing later.

\vspace{1em}

\textbf{Semi-Active Schedule}. A feasible non-preemptive schedule is called
semi-active if no operation can be completed earlier without changing the order
of processing on any one of the machines.

\vfill
taken from [cite:@pinedoSchedulingTheoryAlgorithms2016]

* Tassel et al.

* Traffic scheduling problem
- total completion time $\sum C_j$
- release dates $r_j$
- chains $j_1 \rightarrow j_2 \rightarrow \dots \rightarrow j_k$
- setup times (switch-over) $s_{ij}$

* References
  \begingroup
  \renewcommand{\section}[2]{}
  \bibliography{references}
  \bibliographystyle{plainnat}
  \endgroup

  $\;$
