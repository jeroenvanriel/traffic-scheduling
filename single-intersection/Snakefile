import pandas as pd
import os


# algorithmic parameters
exact_gap = 0.00
exact_timelimit = 5*60
horizon = 1

# experiment parameters
N = 10
spec_file = "exps/spec2.csv"
specs = range(pd.read_csv(spec_file).shape[0])
samples = range(N)


## main targets

rule all:
    input:
        "data/reports/plot.pdf",

        # instance visualizations
        expand("data/instances/instance_{spec}_{sample}.pdf", spec=specs, sample=samples),

        # schedule visualizations
        expand("data/schedules/exhaustive_{spec}_{sample}.pdf", spec=specs, sample=samples),
        expand("data/schedules/exact_{spec}_{sample}.pdf", spec=specs, sample=samples),
        expand("data/schedules/simple_{spec}_{sample}.pdf", spec=specs, sample=samples),
        expand("data/schedules/dqn_{spec}_{sample}.pdf", spec=specs, sample=samples),
        expand("data/schedules/dqntest_{spec}_{sample}.pdf", spec=specs, sample=samples),


## data generation

rule extract_specs:
    """We use a single .csv file to edit the distribution specifications in one
    place, but we generate individual files to help with tracking what needs to be
    recomputed whenever someting is (partly) changed."""
    input: spec_file
    output: expand("data/specs/spec_{spec}.npz", spec=specs)
    conda: "envs/base.yaml"
    script: "extract_specs.py"

rule generate_samples:
    input:
        "data/specs/spec_{spec}.npz",
        "2_lanes_platoons.py",  # to track dependency
    output: expand("data/instances/instance_{{spec}}_{sample}.npz", sample=samples)
    conda: "envs/base.yaml"
    script: "generate.py"

rule visualize_instances:
    input: "data/instances/instance_{spec}_{sample}.npz"
    output: "data/instances/instance_{spec}_{sample}.pdf"
    conda: "envs/plot.yaml"
    script: "visualize_instance.py"


## training

rule train_dqn:
    input:
        "data/specs/spec_{spec}.npz",
        "2_lanes_platoons.py",  # to track dependency
        "dqn.py",  # to track dependency
    output: "data/runs/dqn_{spec}/model.pth"
    params: horizon=horizon
    conda: "envs/pytorch.yaml"
    script: "train_dqn.py"

rule train_dqntest:
    input:
        expand("data/instances/instance_{{spec}}_{sample}.npz", sample=samples),
        "dqn.py",  # to track dependency
    output: "data/runs/dqntest_{spec}/model.pth"
    params: horizon=horizon
    conda: "envs/pytorch.yaml"
    script: "train_dqntest.py"

rule train_ppo:
    input:
        "data/specs/spec_{spec}.npz",
        "2_lanes_platoons.py",  # to track dependency
        "ppo.py",  # to track dependency
    output: "data/runs/ppo_{spec}/model.pth"
    params: horizon=horizon
    conda: "envs/pytorch.yaml"
    script: "train_ppo.py"


## evaluation

rule eval_exact:
    input: "data/instances/instance_{spec}_{sample}.npz"
    output: "data/evals/exact_{spec}_{sample}.npz"
    params:
        gap=exact_gap,
        timelimit=exact_timelimit,
        consolelog=False,
        logfile="data/log/exact_{spec}_{sample}.log"
    conda: "envs/gurobi.yaml"
    script: "exact.py"

rule eval_exhaustive:
    input: "data/instances/instance_{spec}_{sample}.npz"
    output: "data/evals/exhaustive_{spec}_{sample}.npz"
    conda: "envs/base.yaml"
    script: "eval_exhaustive.py"

rule eval_simple:
    input: "data/instances/instance_{spec}_{sample}.npz"
    output: "data/evals/simple_{spec}_{sample}.npz"
    conda: "envs/pytorch.yaml"
    script: "eval_simple.py"

rule eval_dqn:
    input:
        "data/runs/{model,dqn|dqntest}_{spec}/model.pth",
        expand("data/instances/instance_{{spec}}_{sample}.npz", sample=samples),
    output: expand("data/evals/{{model,dqn|dqntest}}_{{spec}}_{sample}.npz", sample=samples)
    params: horizon=horizon
    conda: "envs/pytorch.yaml"
    script: "eval_dqn.py"

rule eval_ppo:
    input:
        "data/runs/ppo_{spec}/model.pth",
        expand("data/instances/instance_{{spec}}_{sample}.npz", sample=samples),
    output: expand("data/evals/ppo_{{spec}}_{sample}.npz", sample=samples)
    params: horizon=horizon
    conda: "envs/pytorch.yaml"
    script: "eval_ppo.py"


## reporting

rule plot_schedules:
    input: "data/evals/{type}_{spec}_{sample}.npz"
    output: "data/schedules/{type}_{spec}_{sample}.pdf"
    conda: "envs/plot.yaml"
    script: "visualize_schedule.py"

rule plot_results:
    input:
        **{ 'spec_file': spec_file },
        **{ f"exact_{spec}": [f"data/evals/exact_{spec}_{sample}.npz" for sample in samples] for spec in specs },
        **{ f"exhaustive_{spec}": [ f"data/evals/exhaustive_{spec}_{sample}.npz" for sample in samples ] for spec in specs },
        **{ f"simple_{spec}": [ f"data/evals/simple_{spec}_{sample}.npz" for sample in samples ] for spec in specs },
        **{ f"dqn_{spec}": [ f"data/evals/dqn_{spec}_{sample}.npz" for sample in samples ] for spec in specs },
        **{ f"dqntest_{spec}": [ f"data/evals/dqntest_{spec}_{sample}.npz" for sample in samples ] for spec in specs },
        **{ f"ppo_{spec}": [ f"data/evals/ppo_{spec}_{sample}.npz" for sample in samples ] for spec in specs },
    output: "data/reports/plot.pdf"
    params: n_specs=len(specs)
    conda: "envs/plot.yaml"
    script: "plot.py"
