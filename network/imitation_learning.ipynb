{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d82cbba-7986-4a0f-b63f-8900776794a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeroen/repos/traffic-scheduling/network\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "tqdm.pandas()\n",
    "import math, time\n",
    "import matplotlib.pyplot as plt\n",
    "%cd /home/jeroen/repos/traffic-scheduling/network/\n",
    "from generate import generate_grid_network, generate_simple_instance\n",
    "from automaton import Automaton\n",
    "from exact import solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d8b2b0-44ac-433b-8b45-5ce5e43035e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import argmax\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06da948-e939-48b1-aec3-c07ea27fbcbb",
   "metadata": {},
   "source": [
    "# Crossing time scheduling in network of intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e51aa-76cb-4f27-b363-cb9215bc6463",
   "metadata": {},
   "source": [
    "We analyze the efficiency of constructive heuristics for the crossing time scheduling problem in grid-like (like Manhattan) networks of intersections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a099e18-4699-423a-beda-c54300912813",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5f0b3-610a-4a00-a4f5-fd1de2e5abac",
   "metadata": {},
   "source": [
    "Generate a small grid network and some instances with a fixed number of arrivals per route. In the next section, we solve these instances to optimality using mixed-integer linear programming, from which we later extract the expert demonstration as observation-action pairs. We use the term observations because it is the result of a static non-parameterized transformation on which the parameterized model is then fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2edcc52e-5cb7-4171-9a73-827312b01bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([\n",
    "    [5, 2, 1],\n",
    "    [5, 3, 1],\n",
    "    [5, 3, 2],\n",
    "], columns=['n_arrivals', 'grid_m', 'grid_n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a035a81-5759-42e7-9cfb-05be80317896",
   "metadata": {},
   "source": [
    "Generate some grid networks and store it together with the routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1570bd3-9339-48fa-8839-8631703d8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['G', 'routes']] = data.apply(lambda row: generate_grid_network(row['grid_m'], row['grid_n']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7809528-4a28-4b28-8e76-dd516f0abed9",
   "metadata": {},
   "source": [
    "We can load the train and test data sets from disk. Skip the next computations and the next section when the optimal solutions have already been computed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96dc246c-ad37-4817-8650-e49f34064de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = {}, {}\n",
    "for i, row in data.iterrows():\n",
    "    train[i] = pd.read_pickle(f'data/train_{i}.pkl')\n",
    "    test[i] = pd.read_pickle(f'data/test_{i}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96f58d-9d55-4f8d-8753-7383769435b9",
   "metadata": {},
   "source": [
    "For each specification, we generate some training instances and some test instances that will be used in the final optimality evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d28f63-e1a5-4c43-bc7b-021703738fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train, N_test = 500, 100\n",
    "train, test = {}, {}\n",
    "for i, row in data.iterrows():\n",
    "    f = lambda: generate_simple_instance(row['G'], row['routes'], arrivals_per_route=row['n_arrivals'])\n",
    "    train[i] = pd.DataFrame(zip([f() for _ in range(N_train)]), columns=['instance'])\n",
    "    test[i] = pd.DataFrame(zip([f() for _ in range(N_test)]), columns=['instance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743614c-f91b-4295-92a4-65ccdcc9e29c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Compute optimal solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674f7e4f-4fbe-413f-b1dd-ecc9c8735b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 5, grid size 2 x 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1361c613404daa818d2053c03e30f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48bbbbec8c3446f8737c5365daab08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 5, grid size 3 x 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7fa48e61b94b3d8a512fcb47ed1a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7aa8edbb76444acbf523be552c296cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 5, grid size 3 x 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f85d698acc142858e3608edd40c1308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba0a2e8c8a94adaa57378002b7bae38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total computation time: 1030.4407222270966\n"
     ]
    }
   ],
   "source": [
    "timelimit_opt = 60\n",
    "\n",
    "def solve_instance(x):\n",
    "    res = solve(x['instance'], timelimit=timelimit_opt)\n",
    "    return res['y'], res['obj'], res['done'], res['gap'], res['time']\n",
    "\n",
    "start = time.time()\n",
    "for i, row in data.iterrows():\n",
    "    print(f\"set {row['n_arrivals']}, grid size {row['grid_m']} x {row['grid_n']}\")\n",
    "    cols = ['opt_y', 'opt_obj', 'opt_done', 'opt_gap', 'opt_time']\n",
    "    train[i][[*cols]] = train[i].progress_apply(solve_instance, axis=1, result_type='expand')\n",
    "    test[i][[*cols]] = test[i].progress_apply(solve_instance, axis=1, result_type='expand')\n",
    "\n",
    "    # save to disk\n",
    "    train[i].to_pickle(f'data/train_{i}.pkl')\n",
    "    test[i].to_pickle(f'data/test_{i}.pkl')\n",
    "print(f'total computation time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb2a0e-2a79-4149-9a0f-20d763089007",
   "metadata": {},
   "source": [
    "Next, we use the optimal crossing time schedules to backtrack the actions for the automaton that lead to this optimal schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfdcc0c-02e5-4a7c-8b16-bd7c2ac7e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_route_order(row):\n",
    "    \"\"\"Compute the order in which vehicles pass each intersection\n",
    "    based on the order of the route to which the vehicles belong.\"\"\"\n",
    "    instance = row['instance']\n",
    "    schedule = row['opt_y']\n",
    "    route_order = {}\n",
    "    indices = schedule.keys() # (r, k, v) tuples\n",
    "    for v in instance['G'].intersections:\n",
    "        route_order[v] = sorted(filter(lambda x: x[2] == v, indices), key=lambda i: schedule[i])\n",
    "        route_order[v] = list(map(lambda x: x[0], route_order[v])) # take route index r\n",
    "    return [route_order] # to prevent unpacking in DataFrame\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    train[i][['opt_route_order']] = train[i].apply(compute_route_order, axis=1, result_type='expand')\n",
    "    # save to disk\n",
    "    train[i].to_pickle(f'data/train_{i}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74718d-fa17-4dd2-96ac-c134df629d4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exhaustive policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc5280f-c7ac-406c-92d0-6cb8657dd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import routes_at_intersection\n",
    "\n",
    "def earliest_route(automaton, v):\n",
    "    \"\"\"Get the route with the earliest arrival at intersection v.\"\"\"\n",
    "    first_vehicles = { r: automaton.D.nodes[r, k, v]['LB']\n",
    "                      for r in automaton.routes_at_intersection[v]\n",
    "                      for k in automaton.order_indices[r] }\n",
    "    return min(first_vehicles, key=first_vehicles.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6013f66e-f9c2-4805-8004-616b4ec9b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import topological_sort\n",
    "\n",
    "def intersection_done(automaton, v):\n",
    "    return all(len(automaton.unscheduled[r, v]) == 0 for r in automaton.routes_at_intersection[v])\n",
    "\n",
    "def threshold_heuristic(instance, threshold=0):\n",
    "    automaton = Automaton(instance)\n",
    "\n",
    "    # visit intersections in topological order\n",
    "    # execute exhaustive policy at intersection v\n",
    "    G = instance['G']\n",
    "    for v in topological_sort(G.subgraph(G.intersections)):\n",
    "        routes = list(automaton.routes_at_intersection[v]) # copy as list\n",
    "\n",
    "        # start with the route with the earliest vehicle\n",
    "        r = earliest_route(automaton, v)\n",
    "        automaton.step(r, v)\n",
    "        while not intersection_done(automaton, v):\n",
    "            # next route candidate\n",
    "            r_next = routes[(routes.index(r) + 1) % len(routes)]\n",
    "            \n",
    "            # next vehicle exists on current route\n",
    "            if len(automaton.unscheduled[r, v]) > 0:\n",
    "                k = automaton.last_scheduled_order[r, v]\n",
    "                # earliest crossing time of next vehicle on this route\n",
    "                LB_next = automaton.D.nodes[r, k + 1, v]['LB']\n",
    "                # check threshold condition\n",
    "                if automaton.D.nodes[r, k, v]['LB'] + instance['rho'] + threshold >= LB_next:\n",
    "                    # continue on this route\n",
    "                    automaton.step(r, v)\n",
    "                    continue\n",
    "            else:\n",
    "                routes.remove(r)\n",
    "\n",
    "            r = r_next\n",
    "            automaton.step(r, v)\n",
    "\n",
    "    return automaton.get_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3eddd4-0793-49e3-adda-caedc4cd7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_exhaustive(test, set_id):\n",
    "    tqdm.pandas(desc=f\"{set_id} evaluating\")\n",
    "    return test.progress_apply(lambda x: threshold_heuristic(x['instance'], threshold=0), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683b9465-80a0-4834-8dd4-f3b75093591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a333f5da4614429b23fc4a7e799d65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a04bff116545dcbe182a50d5d0902c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1 evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ccbe51bb874169831404064ae67b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2 evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['exhaustive_obj'] = data.apply(lambda row: eval_exhaustive(test[row.name], row.name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d7f7a-e3f6-459c-bb56-522e10cfea84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## GNN heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad92a8-05ca-4a68-a858-17c5c6cc2e68",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c043617-81b8-4ba8-a5fc-a0a946b18445",
   "metadata": {},
   "source": [
    "For the observations of the GNN model, we **copy the whole disjunctive graph** for each state. Alternatively, we could use some sort of masking for non-final states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b56bb8-1053-4266-8ee5-2c5b72e7f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, BatchNorm1d\n",
    "from torch_geometric.nn import GINConv\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # we need a separate layer for the first iteration, because the initial\n",
    "        # feature dimension in different from the node embedding dimension\n",
    "        lin0 = Sequential(Linear(1, 16), ReLU(), Linear(16, 32), ReLU(), BatchNorm1d(32))\n",
    "        self.gin0 = GINConv(lin0, train_eps=True)\n",
    "\n",
    "        lin1 = Sequential(Linear(32, 32), ReLU(), Linear(32, 32), ReLU(), BatchNorm1d(32))\n",
    "        self.gin1 = GINConv(lin1, train_eps=True)\n",
    "\n",
    "        lin2 = Sequential(Linear(32, 32), ReLU(), Linear(32, 32), ReLU(), BatchNorm1d(32))\n",
    "        self.gin2 = GINConv(lin2, train_eps=True)\n",
    "        \n",
    "        self.lin1 = Linear(32, 32)\n",
    "        self.lin2 = Linear(32, 16)\n",
    "        self.lin3 = Linear(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.gin0(x, edge_index)\n",
    "        x = self.gin1(x, edge_index)\n",
    "        #x = self.gin2(x, edge_index)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin3(x)\n",
    "\n",
    "        return x.squeeze()\n",
    "    \n",
    "    def state_transform(self, automaton):\n",
    "        state = automaton.D.copy()\n",
    "        # remove all edges connecting to or from nodes that are done\n",
    "        state.remove_done_edges()\n",
    "        return state\n",
    "\n",
    "    def  inverse_action_transform(self, automaton, r, v):\n",
    "        # Instead of (r, v) pairs, which are used in the automaton, we\n",
    "        # use the full (r, k, v) tuple, like in Zhang et al., where they\n",
    "        # use the full operation a_t = O_{ij} as action.\n",
    "        k = automaton.unscheduled[r, v][0]\n",
    "        return r, k, v\n",
    "\n",
    "gnn_model = GNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fafd8-0799-45d5-89f6-f63af9aa7ab7",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39d0e9-b51c-494a-9bf2-5f81815a7c0e",
   "metadata": {},
   "source": [
    "Collect all the state-action pairs in a single dataset to support mini-batching via the `DataLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4e2c6c63-5ac0-44f1-a994-133c9747f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from util import vehicle_indices, route_indices\n",
    "\n",
    "# force double during conversion\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "instance = generate_simple_instance(G, routes, arrivals_per_route=A)\n",
    "automaton = Automaton(instance)\n",
    "# actions are all vehicle-intersection pairs\n",
    "valid_gnn_actions = list(automaton.D.nodes)\n",
    "\n",
    "def generate_graphs(G, routes):\n",
    "    \"\"\"Generate a set of graphs based on optimal schedules.\"\"\"\n",
    "    graphs = []\n",
    "    for instance, y in train_data:\n",
    "        states, actions, _ = collect_state_action_pairs(instance, y, model)\n",
    "        for state, action in zip(states, actions):        \n",
    "            graph = from_networkx(state, group_node_attrs=['LB'])\n",
    "            graph.action = valid_gnn_actions.index(action) # map to integers indices\n",
    "            graphs.append(graph)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249123d5-180a-47d6-97d5-55f985b5cf88",
   "metadata": {},
   "source": [
    "What are the following attributes:\n",
    "\n",
    "- label\n",
    "- weight\n",
    "- batch: index of graph to which this node belongs\n",
    "- ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acda4ba-85df-477e-a6be-1d168dd269af",
   "metadata": {},
   "source": [
    "**Assumption**: node order (see `batch.label`) is the same among all state graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe94ad9-c23c-4ab4-875f-55bf82d60e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import softmax\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def stacked_batch(batch, indices):\n",
    "    \"\"\"Transform a 'flat batch' of dimension (N*B), where N is number of graphs\n",
    "    in batch and B is number of nodes per graph, to a 'stacked batch' of\n",
    "    dimension (N, B), based on batch indices `batch.batch`.\"\"\"\n",
    "    unique = torch.unique(indices)\n",
    "    return torch.vstack([batch[indices == i] for i in unique])\n",
    "\n",
    "data_train = DataLoader(generate_data(G, routes, N), batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8c003-9dc7-4712-b197-b14ef48b9eb2",
   "metadata": {},
   "source": [
    "We now have the following classification task: map disjunctive **graph** to an **action** (route-intersection pair). We use a GIN to compute an embedding for each node, which is fed through an MLP and softmax to produce a probability over nodes. In Zhang et al., each action corresponds to a unique node, encoding the operations that is dispatched next. However, we only really need to provide a route-intersection pair, but **how to exploit this in the policy model**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dbc2f0-a4c3-49dc-9250-87a9fb566150",
   "metadata": {},
   "source": [
    "The GNN computes node embeddings, which are mapped to a score for each node. We compute the softmax over the scores of the nodes and then compute the negative log likelihood loss for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd4a6e-dcd1-4381-b342-dabb21891cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 20\n",
    "print(\"\\ntraining model\\n\")\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    loss_total = 0\n",
    "    print(f'epoch: {i}')\n",
    "    for batch in data_train:\n",
    "        optimizer.zero_grad()\n",
    "        # compute node scores\n",
    "        y = model(batch)\n",
    "        y = y.masked_fill(~batch.action_mask.bool(), -torch.inf) # ignore invalid\n",
    "        # restack for loss calculation\n",
    "        pred = stacked_batch(y, batch.batch)\n",
    "        target = batch.action\n",
    "        loss = F.cross_entropy(pred, target)\n",
    "        loss.backward()\n",
    "        loss_total += loss\n",
    "        optimizer.step()\n",
    "    print(f\"loss: {loss_total.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba12de3f-c53e-450f-a104-d65ef4c48991",
   "metadata": {},
   "source": [
    "### Evaluate imitation of GNN policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2531231-394c-4fbf-92d9-243fd9dd4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import argmax\n",
    "\n",
    "def evaluate_imitation(model, N=100):\n",
    "    \"\"\"Measure accuracy based on unseen expert demonstration state-action pairs.\"\"\"\n",
    "    model.eval()\n",
    "    print(\"\\ngenerating test data\\n\")\n",
    "    data_test = DataLoader(generate_data(G, routes, N))\n",
    "    total_correct = 0\n",
    "    print(\"\\nevaluating imitation accuracy\\n\")\n",
    "    for batch in tqdm(data_test):\n",
    "        # compute node scores\n",
    "        y = model(batch)\n",
    "        # mask invalid actions (set to -inf)\n",
    "        y = y.masked_fill(~batch.action_mask.bool(), -torch.inf)\n",
    "        # restack for loss calculation\n",
    "        pred = stacked_batch(y, batch.batch)\n",
    "        pred = argmax(pred, dim=1)\n",
    "        target = batch.action\n",
    "        total_correct += pred == target\n",
    "    print(f\"accuracy: {total_correct.item() / len(data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1897aef-dc6e-4306-ba23-51d944e82e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_imitation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895bd144-8972-4f42-9c17-1385e74f13d9",
   "metadata": {},
   "source": [
    "### Evaluate scheduling of GNN policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7f05b-9379-4e89-9d93-b9e881af3515",
   "metadata": {},
   "source": [
    "Current definition of objective in `exact.py` is total sum of crossing times, including at exit points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f61be9-2fd6-4adb-882c-08824aea8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import masked_select\n",
    "\n",
    "def evaluate_scheduling(model, N=100):\n",
    "    \"\"\"Evaluate average objective when executing the policy over full\n",
    "    unseen problem instances compared to average optimal objective.\"\"\"\n",
    "    print(\"\\nevaluating policy\\n\")\n",
    "    model.eval()\n",
    "    obj_opt = 0\n",
    "    obj_model = 0\n",
    "    for _ in trange(N):\n",
    "        instance = generate_simple_instance(G, routes, arrivals_per_route=A)\n",
    "\n",
    "        # solve optimally\n",
    "        y, obj = solve(instance)\n",
    "        obj_opt += obj\n",
    "\n",
    "        # TEST objective definition\n",
    "        # _, actions, _ = collect_state_action_pairs(instance, y)\n",
    "\n",
    "        # execute learned heuristic\n",
    "        automaton = Automaton(instance)\n",
    "        while not automaton.done:\n",
    "            state = automaton.D\n",
    "            graph = from_networkx(state, group_node_attrs=['LB'])\n",
    "            # compute node scores\n",
    "            y = model(graph)\n",
    "            # mask invalid actions (set to -inf)\n",
    "            y = y.masked_fill(~graph.action_mask.bool(), -torch.inf)\n",
    "            y = argmax(y)\n",
    "            # translate index back to actual action\n",
    "            action = valid_gnn_actions[y]\n",
    "            r, k, v = action\n",
    "            # execute action on automaton\n",
    "            automaton.step(r, v)\n",
    "\n",
    "        # TEST objective definition\n",
    "        # for action in actions:\n",
    "        #     r, k, v = action\n",
    "        #     automaton.step(r, v)\n",
    "\n",
    "        # compute obj from automaton\n",
    "        obj_model += automaton.get_obj()\n",
    "\n",
    "    print(f\"obj_opt={obj_opt / N} vs obj_model={obj_model / N}\")\n",
    "    print(f\"approximation ratio={obj_model / obj_opt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd41aa-95e0-4da4-828e-41a6ed3e6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_scheduling(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837d50c-2cf0-48e3-8862-dbfd6d92ee4f",
   "metadata": {},
   "source": [
    "## RNN heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebd478-5059-4bb4-b14e-fdb15504517e",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e2a1e-5e25-484a-9da7-d7f8c796cca9",
   "metadata": {},
   "source": [
    "The observations for the RNN model are the collection of _horizons_ for each route-intersection pair and flags that indicate which route was served during the last step of the automaton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b67a6b2-2767-4e90-adbd-41aaf656b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "    def __init__(self, n_crossings, max_horizon):\n",
    "        \"\"\"n_crossings = number of (route, intersection) pairs\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_crossings = n_crossings\n",
    "        self.max_horizon = max_horizon\n",
    "\n",
    "        self.rnn_out = 32\n",
    "        self.rnns = [ nn.RNN(1, self.rnn_out).cuda() for _ in range(n_crossings) ]\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.n_crossings * (1 + self.rnn_out), 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.n_crossings),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        N = obs.size()[0] # batch size\n",
    "        embedding = torch.zeros((N, self.n_crossings, 1 + self.rnn_out))\n",
    "        for n in range(N):\n",
    "            for c in range(self.n_crossings):\n",
    "                # first bool is done flag\n",
    "                done = int(obs[n, c, 0].item())\n",
    "                \n",
    "                # second bool is last scheduled route flag\n",
    "                last = int(obs[n, c, 1].item())\n",
    "                embedding[n, c, 0] = last\n",
    "\n",
    "                # third number indicates length of the horizon\n",
    "                length = int(obs[n, c, 2].item())\n",
    "                if length == 0:\n",
    "                    continue\n",
    "\n",
    "                # rest of sequence is actual horizon\n",
    "                horizon = obs[n, c, 3:3+length]\n",
    "                # reverse (\"flip up down\") the horizon\n",
    "                inp = torch.flipud(horizon)\n",
    "                # add dimension as required by RNN\n",
    "                out, _ = self.rnns[c](torch.unsqueeze(inp, 1))\n",
    "                # take the output at the last step as the rest of the embedding                \n",
    "                embedding[n, c, 1:] = out[-1]\n",
    "\n",
    "        flattened = torch.flatten(embedding, 1, 2)\n",
    "        return self.network(flattened.cuda())\n",
    "\n",
    "    def state_transform(self, automaton):\n",
    "        # compute minimum LB across all unscheduled nodes in disjunctive graph\n",
    "        LBs = []\n",
    "        for _, data in automaton.D.nodes(data=True):\n",
    "            if not data['done']:\n",
    "                LBs.append(data['LB'])\n",
    "        min_LB = min(LBs)\n",
    "\n",
    "        # flag: crossing done\n",
    "        done = np.zeros((self.n_crossings, 1))\n",
    "        # flag: last scheduled route at intersection (0 before first action)\n",
    "        last = np.zeros((self.n_crossings, 1))\n",
    "        # (truncated) horizon\n",
    "        length = np.zeros((self.n_crossings, 1), dtype=np.uint32)\n",
    "        obs = np.zeros((self.n_crossings, self.max_horizon))\n",
    "\n",
    "        for i, (r, v) in enumerate(automaton.crossing_indices):\n",
    "            done[i] = automaton.crossing_done[r, v]\n",
    "            if automaton.last_scheduled_route[v] is not None:\n",
    "                last[i] = int(automaton.last_scheduled_route[v] == r)\n",
    "                \n",
    "            horizon_length = min(len(automaton.unscheduled[r, v]), self.max_horizon)\n",
    "            length[i] = horizon_length\n",
    "            if horizon_length > 0:\n",
    "                full_horizon = [automaton.D.nodes[r, k, v]['LB'] for k in automaton.unscheduled[r, v]]\n",
    "                # subtract minimal LB and truncate to max_horizon\n",
    "                obs[i, :horizon_length] = np.array(full_horizon[:horizon_length]) - min_LB\n",
    "\n",
    "        # create ragged array; first bool is \"done flag\", second bool is \"last route flag\",\n",
    "        # third number indicates length of the horizon, rest is horizon itself\n",
    "        out = np.hstack([done, last, length, obs])\n",
    "        out = np.expand_dims(out, axis=0) # to allow stacking with actions\n",
    "        return torch.as_tensor(out, dtype=torch.float, device=torch.device('cuda'))\n",
    "\n",
    "    def inverse_action_transform(self, automaton, r, v):\n",
    "        out = automaton.crossing_indices.index((r, v))\n",
    "        return torch.as_tensor(out, dtype=torch.float, device=torch.device('cuda'))\n",
    "\n",
    "    def action_transform(self, automaton, out):\n",
    "        # mask invalid actions (set to -inf)\n",
    "        for r, v in automaton.crossing_indices:\n",
    "            if automaton.crossing_done[r, v]:\n",
    "                i = automaton.crossing_indices.index((r, v))\n",
    "                out[i] = -torch.inf\n",
    "        # greedy inference\n",
    "        i = argmax(out)\n",
    "        # translate index back to actual action\n",
    "        r, v = automaton.crossing_indices[i]\n",
    "        return r, v\n",
    "\n",
    "    def heuristic(self, automaton):\n",
    "        \"\"\"Perform the actual trained heuristic.\"\"\"\n",
    "        return self.action_transform(automaton, self.forward(self.state_transform(automaton)).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1aef35-efcd-4dfe-b024-34ff365f0c1e",
   "metadata": {},
   "source": [
    "### Training with imitation learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e38cc3-894e-4eb5-aaea-8818730d611e",
   "metadata": {},
   "source": [
    "Note that the global order of actions is not unique: the order in which intersections are considered does not matter for the final schedule. Therefore, we can pick any or multiple sequences of intersections and replay the corresponding sequence of actions on the automaton to generate the corresponding sequence of observation-action pairs that act as the expert demonstration. For example, we can randomly select some next intersection that is not yet done. Another possible approach is to add for each possible next intersection the next action that leads to the given optimal schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a3639b3-2073-4563-8471-4100370680e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state_action_pairs(train, model, set_id):\n",
    "    \"\"\"We should rather say \"observation\"-action pair, because the static transformation is applied.\"\"\"\n",
    "    states, actions = [], []\n",
    "    for _, row in tqdm(train.iterrows(), desc=f\"{set_id} extracting\", total=train.shape[0], leave=False):\n",
    "        instance = row['instance']\n",
    "        # deep copy of route_order with reversed lists to use as stacks\n",
    "        route_order = { v: list(reversed(row['opt_route_order'][v])) for v in row['opt_route_order'] }\n",
    "\n",
    "        # backtrack observations and actions for the optimal schedule\n",
    "        automaton = Automaton(instance)\n",
    "        # keep track of which intersections still have unscheduled vehicles\n",
    "        pending_intersections = list(route_order.keys())\n",
    "\n",
    "        last_intersection = None\n",
    "        \n",
    "        while not automaton.done:        \n",
    "            # add action for each pending intersection\n",
    "            for v in pending_intersections:\n",
    "                r = route_order[v][-1]\n",
    "                # record (transformed) state-action pair\n",
    "                states.append(model.state_transform(automaton))\n",
    "                actions.append(model.inverse_action_transform(automaton, r, v))\n",
    "\n",
    "            # 1. randomly choose which action is actually executed\n",
    "            #v = choice(pending_intersections)\n",
    "\n",
    "            # 2. fixed order (so action sequence \"along the boundary\")\n",
    "            #v = pending_intersections[0]\n",
    "\n",
    "            # 3. loop in linear order (given by 'opt_route_order')\n",
    "            # if last_intersection in pending_intersections and len(pending_intersections) >= 2:\n",
    "            #     i = pending_intersections.index(last_intersection)\n",
    "            #     v = pending_intersections[(i + 1) % len(pending_intersections)]\n",
    "            # else:\n",
    "            #     v = pending_intersections[0]\n",
    "            # last_intersection = v\n",
    "            \n",
    "            r = route_order[v].pop()\n",
    "            \n",
    "            states.append(model.state_transform(automaton))\n",
    "            actions.append(model.inverse_action_transform(automaton, r, v))\n",
    "            # perform action\n",
    "            automaton.step(r, v)\n",
    "    \n",
    "            # remove pending intersection when done\n",
    "            if len(route_order[v]) == 0:\n",
    "                pending_intersections.remove(v)\n",
    "\n",
    "    return states, actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c662a51-71fe-4fa1-bb62-a0df5f66ab8f",
   "metadata": {},
   "source": [
    "As a sanity check, we replay the actions for a single instance and verify whether we end up with the same objective. This does not work if the state-action set contains duplicate, which we use to train a separate model for each crossing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e870d43-8766-403a-9005-f822e93466b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train[0].iloc[0] # first instance of first data set\n",
    "automaton = Automaton(row['instance'])\n",
    "model = RNNModel(len(automaton.crossing_indices), 10) # some dummy model\n",
    "\n",
    "# extract and replay actions\n",
    "_, actions = extract_state_action_pairs(pd.DataFrame(row).T, model, 0)\n",
    "for action in actions:\n",
    "    r, v = automaton.crossing_indices[int(action.item())]\n",
    "    automaton.step(r, v)\n",
    "\n",
    "opt_y = row['opt_y'] # check with optimal schedule\n",
    "for node, LB in automaton.D.nodes.data('LB'):\n",
    "    assert math.isclose(LB, opt_y[node]), \"crossing times do not match\"\n",
    "\n",
    "assert automaton.done, \"automaton not done\"\n",
    "assert math.isclose(row['opt_obj'], automaton.get_obj()), \"final objectives do not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd83d9-6df2-4a82-b375-3d07b5a020e6",
   "metadata": {},
   "source": [
    "Main training loop with fixed number of total batches to process and validation (in terms of imitation loss) after a given number of batches. It might be more sensible to compute validation in terms of scheduling performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a33441c0-c9c3-44ab-8501-08d32cf49fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from copy import deepcopy\n",
    "\n",
    "neural_train_losses = []\n",
    "neural_val_losses = []\n",
    "neural_train_times = {}\n",
    "\n",
    "# instead of epochs, we provide the total number of individual training steps,\n",
    "# to support fair comparison across different training data sets\n",
    "total_steps = 1000\n",
    "# compute validation loss each time this number of steps has been processed\n",
    "val_steps = 20\n",
    "# we define both the above numbers globally, because we need it to determine\n",
    "# the correct time epochs when plotting the validation losses\n",
    "\n",
    "def train_rnn(train, model, set_id):    \n",
    "    start = time.time()\n",
    "\n",
    "    states, actions = extract_state_action_pairs(train, model, set_id)\n",
    "\n",
    "    batch_size = 20\n",
    "    val_frac = 0.1 # fraction of state-action pairs used for validation\n",
    "\n",
    "    state_action_pairs = TensorDataset(torch.vstack(states), torch.vstack(actions))\n",
    "    train_set, val_set = random_split(state_action_pairs, [1 - val_frac, val_frac])    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set)\n",
    "\n",
    "    learning_rate = 5e-4\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    params = []\n",
    "    step = 0\n",
    "    with tqdm(total=total_steps, desc=f\"{set_id} training\", leave=False) as pbar:\n",
    "        while True:\n",
    "            for s, a in train_loader:\n",
    "                # perform a single training step\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                loss = cross_entropy(model(s), a.squeeze().long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "                step += 1\n",
    "                pbar.update(1)\n",
    "                \n",
    "                if step % val_steps == 0:\n",
    "                    # store current model parameters        \n",
    "                    params.append(model.state_dict())\n",
    "                    # validate current model\n",
    "                    model.eval()\n",
    "                    val_loss = 0\n",
    "                    for s, a in val_loader:\n",
    "                        val_loss += cross_entropy(model(s).squeeze(), a.squeeze().long())\n",
    "                    val_losses.append(val_loss.detach().cpu() / len(val_loader)) # average over validation set\n",
    "\n",
    "                if step >= total_steps: break # ...out of inner loop\n",
    "            if step >= total_steps: break # ...out of outer loop\n",
    "\n",
    "    # select model with minimal validation loss\n",
    "    i = val_losses.index(min(val_losses))\n",
    "    model.load_state_dict(params[i])\n",
    "\n",
    "    # record data for reporting\n",
    "    neural_train_times[set_id] = time.time() - start\n",
    "    neural_train_losses.append(train_losses)\n",
    "    neural_val_losses.append(val_losses)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ec957-fe1e-4ae8-8cbc-2aafd6c5815a",
   "metadata": {},
   "source": [
    "### Evaluate recurrent heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af498bc-4587-4fcb-b7da-d6edeff1c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rnn(train, test, set_id):\n",
    "    # get number of crossings, which is number of actions\n",
    "    automaton = Automaton(train['instance'][0])\n",
    "    n_crossings = len(automaton.crossing_indices)\n",
    "    # maximum number of vehicle arrivals to \"look ahead\"\n",
    "    max_horizon = 5\n",
    "    \n",
    "    model = RNNModel(n_crossings, max_horizon).cuda()\n",
    "    model = train_rnn(train, model, set_id)\n",
    "    model.eval()\n",
    "\n",
    "    def eval_scheduling(row):\n",
    "        automaton = Automaton(row['instance'])\n",
    "        while not automaton.done:       \n",
    "            # execute learned heuristic\n",
    "            automaton.step(*model.heuristic(automaton))\n",
    "        return automaton.get_obj()\n",
    "\n",
    "    tqdm.pandas(desc=f\"{set_id} evaluating\")\n",
    "    return test.progress_apply(eval_scheduling, axis=1, result_type='expand').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c46d7a5e-b55b-47f0-a511-d7cde3b7f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2 extracting:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2 training:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9cfd56217247d5be3dfce0b1a5e4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2 evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for set_id in [2]:\n",
    "    data.loc[set_id, 'rnn_obj'] = eval_rnn(train[set_id], test[set_id], set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a0f099-a9d8-4c0b-8040-9266ec0e3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take mean objective and running time over all test instances\n",
    "data['opt_obj'] = data.apply(lambda row: test[row.name]['opt_obj'].mean(), axis=1)\n",
    "data['opt_time'] = data.apply(lambda row: test[row.name]['opt_time'].mean(), axis=1)\n",
    "\n",
    "# compute (relative) approximation ratio\n",
    "data['rnn_gap'] = data.apply(lambda row: row['rnn_obj'] / row['opt_obj'], axis=1)\n",
    "data['exhaustive_gap'] = data.apply(lambda row: row['exhaustive_obj'] / row['opt_obj'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abc98b86-138d-4838-8504-cde1bf844353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_arrivals</th>\n",
       "      <th>grid_m</th>\n",
       "      <th>grid_n</th>\n",
       "      <th>opt_obj</th>\n",
       "      <th>exhaustive_obj</th>\n",
       "      <th>rnn_obj</th>\n",
       "      <th>exhaustive_gap</th>\n",
       "      <th>rnn_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1396.522515</td>\n",
       "      <td>1556.358790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.114453</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2073.633014</td>\n",
       "      <td>2393.751219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.154376</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3869.882353</td>\n",
       "      <td>4578.792285</td>\n",
       "      <td>5174.797099</td>\n",
       "      <td>1.183186</td>\n",
       "      <td>1.337198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_arrivals  grid_m  grid_n      opt_obj  exhaustive_obj      rnn_obj  \\\n",
       "0           5       2       1  1396.522515     1556.358790          NaN   \n",
       "1           5       3       1  2073.633014     2393.751219          NaN   \n",
       "2           5       3       2  3869.882353     4578.792285  5174.797099   \n",
       "\n",
       "   exhaustive_gap   rnn_gap  \n",
       "0        1.114453       NaN  \n",
       "1        1.154376       NaN  \n",
       "2        1.183186  1.337198  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['n_arrivals', 'grid_m', 'grid_n', 'opt_obj', 'exhaustive_obj', 'rnn_obj', 'exhaustive_gap', 'rnn_gap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0127be0-6d11-4471-b669-45b74cb3c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "gs = fig.add_gridspec(nrows=len(neural_train_losses), ncols=1, hspace=0.1, wspace=0.1)\n",
    "axes = gs.subplots(sharex=True, sharey=True)\n",
    "for ax, train_losses, val_losses in zip(axes.T.flatten(), neural_train_losses, neural_val_losses):\n",
    "    ax.plot(train_losses, alpha=0.8, label='training')\n",
    "    val_t = np.array(range(1, 1 + total_steps // val_steps)) * val_steps\n",
    "    ax.plot(val_t, val_losses, '--k', label='validation')\n",
    "    #ax.set(xlabel='step')\n",
    "    \n",
    "for ax, label in zip(axes, ['0', '1', '2']):\n",
    "    ax.set_ylabel(label, size=15)\n",
    "\n",
    "#plt.legend() # single legend in last ax\n",
    "plt.savefig(f'neural_fit.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc5682-6af3-43ab-a09b-96d69e42872f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
