{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d82cbba-7986-4a0f-b63f-8900776794a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jeroen/repos/traffic-scheduling/network\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jeroen/repos/traffic-scheduling/network/\n",
    "from generate_network import generate_simple_instance\n",
    "from automaton import Automaton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f37d78-f88d-4c82-8800-599bdb39dadc",
   "metadata": {},
   "source": [
    "### Obtain expert demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e736a481-4ee4-462f-914d-bc8c471fdafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exact import solve\n",
    "instance = generate_simple_instance()\n",
    "y, obj = solve(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb2a0e-2a79-4149-9a0f-20d763089007",
   "metadata": {},
   "source": [
    "We solve the instance to optimality with an exact method. Next, we use the resulting crossing time schedule to compute actions for the automaton that lead to the same schedule. However, this sequence of actions is not unique: the order in which intersections are considered does not matter for the final schedule. Therefore, we sample some intersection order and replay the sequence of actions on the automaton to generate the corresponding sequence of state-action pairs. At this point, we **copy the whole disjunctive graph** for each state. Alternatively, we could use some sort of masking for non-final states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33441c0-c9c3-44ab-8501-08d32cf49fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from util import vehicle_indices\n",
    "\n",
    "def collect_state_action_pairs(instance, schedule):\n",
    "    \"\"\"Collect states and actions leading to the given schedule.\n",
    "    `schedule` is a dict mapping (route, order, node) tuples to crossing times.\n",
    "    \"\"\"\n",
    "    automaton = Automaton(instance)\n",
    "\n",
    "    # Compute the order in which vehicles pass each intersection\n",
    "    # based on the order of the route to which the vehicles belong.\n",
    "    route_order = {}\n",
    "    indices = schedule.keys() # (r, k, v) tuples\n",
    "    for v in instance['G'].intersections:\n",
    "        # note the minus sign: reverse sorted order, so last route first\n",
    "        route_order[v] = sorted(filter(lambda x: x[2] == v, indices), key=lambda i: -schedule[i])\n",
    "        route_order[v] = list(map(lambda x: x[0], route_order[v])) # take route index\n",
    "    \n",
    "    actions = []\n",
    "    states = [automaton.D.copy()] # initial state is empty disjunctive graph\n",
    "\n",
    "    # keep track of which intersections still have unscheduled vehicles\n",
    "    pending_intersections = list(route_order.keys())\n",
    "    while len(pending_intersections) > 0:\n",
    "        v = choice(pending_intersections)\n",
    "        # we can now pop from back because route_order[v] was reverse sorted\n",
    "        r = route_order[v].pop() \n",
    "        automaton.step(r, v)\n",
    "    \n",
    "        # record action:\n",
    "        # Instead of (r,v) pairs, which are used in the automaton, we\n",
    "        # use the full (r,k,v) tuple, like in Zhang et al., where they\n",
    "        # use the full operation a_t = O_{ij} as action.\n",
    "        k = automaton.last_scheduled[r, v]\n",
    "        actions.append((r, k, v))\n",
    "        # record state by copying current disjunctive graph\n",
    "        states.append(automaton.D.copy())\n",
    "    \n",
    "        # remove intersection if done\n",
    "        if len(route_order[v]) == 0:\n",
    "            pending_intersections.remove(v)\n",
    "\n",
    "    return states, actions, automaton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3196d04-451a-47f2-a6dd-1e4ea0fbde30",
   "metadata": {},
   "source": [
    "Verify the reconstruction by replaying the given actions and checking whether we arrive at the same schedule again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d50c10-64ee-4ff4-bf15-b34b59523200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import get_node_attributes\n",
    "import numpy as np\n",
    "\n",
    "states, actions, automaton = collect_state_action_pairs(instance, y)\n",
    "automaton = Automaton(instance)\n",
    "for action in actions:\n",
    "    r, k, v = action\n",
    "    automaton.step(r, v)\n",
    "LB = get_node_attributes(automaton.D, 'LB')\n",
    "np.testing.assert_allclose(np.array(list(LB.values())), np.array(list(y.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a099e18-4699-423a-beda-c54300912813",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5f0b3-610a-4a00-a4f5-fd1de2e5abac",
   "metadata": {},
   "source": [
    "We solve a couple of instances and collect all the state-action pairs in a single dataset to support mini-batching via the `DataLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2c6c63-5ac0-44f1-a994-133c9747f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from util import vehicle_indices, route_indices\n",
    "\n",
    "# force double during conversion\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# number of valid actions is number of intersection-route pairs\n",
    "instance = generate_simple_instance()\n",
    "automaton = Automaton(instance)\n",
    "# actions are all route-intersection pairs\n",
    "valid_actions = list(automaton.D.nodes)\n",
    "num_actions = len(valid_actions)\n",
    "\n",
    "# TODO: generate single network\n",
    "# TODO: generate different vehicle arrivals for this same network\n",
    "\n",
    "def generate_data(N):\n",
    "    \"\"\"Generate set graphs based on solving N problem instances to optimality.\"\"\"\n",
    "    graphs = []\n",
    "    for _ in range(N):\n",
    "        instance = generate_simple_instance()\n",
    "        y, obj = solve(instance)\n",
    "    \n",
    "        states, actions, _ = collect_state_action_pairs(instance, y)\n",
    "        for state, action in zip(states, actions):        \n",
    "            graph = from_networkx(state, group_node_attrs=['LB', 'done'])\n",
    "    \n",
    "            \n",
    "            graph.action = valid_actions.index(action) # map to integers\n",
    "            \n",
    "            graphs.append(graph)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8522d-4b5a-4fd3-b9d4-4e7c420c500d",
   "metadata": {},
   "source": [
    "Obtain and inspect a single batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f401be-720b-4b52-a1b5-88920f0dc134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 93], label=[2], action_mask=[60], weight=[93], x=[60, 2], action=[2], batch=[60], ptr=[3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataLoader(generate_data(10), batch_size=2, shuffle=True)\n",
    "next(iter(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249123d5-180a-47d6-97d5-55f985b5cf88",
   "metadata": {},
   "source": [
    "What are the following attributes:\n",
    "\n",
    "- label\n",
    "- weight\n",
    "- batch: index of graph to which this node belongs\n",
    "- ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acda4ba-85df-477e-a6be-1d168dd269af",
   "metadata": {},
   "source": [
    "**Assumption**: node order (see `batch.label`) is the same among all state graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d7f7a-e3f6-459c-bb56-522e10cfea84",
   "metadata": {},
   "source": [
    "### Imitation learning with GNN policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8c003-9dc7-4712-b197-b14ef48b9eb2",
   "metadata": {},
   "source": [
    "We now have the following classification task: map disjunctive **graph** to an **action** (route-intersection pair). We use a GIN to compute an embedding for each node, which is fed through an MLP and softmax to produce a probability over nodes. In Zhang et al., each action corresponds to a unique node, encoding the operations that is dispatched next. However, we only really need to provide a route-intersection pair, but **how to exploit this in the policy model**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b3e9402-ff39-4576-b6a2-b9211bf96179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # we need a separate layer for the first iteration, because the initial\n",
    "        # feature dimension in different from the node embedding dimension\n",
    "        lin0 = Sequential(Linear(2, 32))\n",
    "        self.gin0 = GINConv(lin0, train_eps=True)\n",
    "\n",
    "        lin = Sequential(Linear(32, 32))\n",
    "        self.gin = GINConv(lin, train_eps=True)\n",
    "        \n",
    "        self.lin1 = Linear(32, 32)\n",
    "        self.lin2 = Linear(32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.gin0(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        for _ in range(1): # the rest of the K-1 iterations\n",
    "            x = self.gin(x, edge_index)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x.squeeze()\n",
    "\n",
    "model = GNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dbc2f0-a4c3-49dc-9250-87a9fb566150",
   "metadata": {},
   "source": [
    "The GNN computes node embeddings, which are mapped to a score for each node. We compute the softmax over the scores of the nodes and then compute the negative log likelihood loss for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c5040c5-e2cd-49c8-9ce0-63da0fb93355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training model\n",
      "\n",
      "epoch: 0\n",
      "loss: 1873.8948934434998\n",
      "epoch: 1\n",
      "loss: 1874.3125676702848\n",
      "epoch: 2\n",
      "loss: 1869.5252868922591\n",
      "epoch: 3\n",
      "loss: 1863.432925770807\n",
      "epoch: 4\n",
      "loss: 1859.0543117467428\n",
      "epoch: 5\n",
      "loss: 1862.4085723285118\n",
      "epoch: 6\n",
      "loss: 1855.2669235564033\n",
      "epoch: 7\n",
      "loss: 1854.8674736717348\n",
      "epoch: 8\n",
      "loss: 1854.5387522919525\n",
      "epoch: 9\n",
      "loss: 1853.0164628663333\n",
      "epoch: 10\n",
      "loss: 1859.0068659607434\n",
      "epoch: 11\n",
      "loss: 1853.9021937203777\n",
      "epoch: 12\n",
      "loss: 1853.012929535769\n",
      "epoch: 13\n",
      "loss: 1853.1915699958354\n",
      "epoch: 14\n",
      "loss: 1852.6229600303213\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch_geometric.utils import softmax\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def stacked_batch(batch, indices):\n",
    "    \"\"\"Transform flat batch of dimension (N*B), where N is number of graphs\n",
    "    in batch and B is number of nodes in graph, to a stacked batch of\n",
    "    dimension (N, B), based on batch indices `batch.batch`.\"\"\"\n",
    "    unique = torch.unique(indices)\n",
    "    return torch.vstack([batch[indices == i] for i in unique])\n",
    "\n",
    "N = 500 # number of instances\n",
    "data_train = DataLoader(generate_data(N), batch_size=10, shuffle=True)\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 15\n",
    "    \n",
    "print(\"\\ntraining model\\n\")\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    loss_total = 0\n",
    "    print(f'epoch: {i}')\n",
    "    for batch in data_train:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute node scores\n",
    "        y = model(batch)\n",
    "        # softmax over node scores per graph, using batch indices\n",
    "        y = softmax(y, batch.batch)\n",
    "        # restack for loss calculation\n",
    "        pred = stacked_batch(y, batch.batch)\n",
    "\n",
    "        target = batch.action\n",
    "        loss = F.cross_entropy(pred, target)\n",
    "        loss.backward()\n",
    "        loss_total += loss\n",
    "        optimizer.step()\n",
    "    print(f\"loss: {loss_total.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba12de3f-c53e-450f-a104-d65ef4c48991",
   "metadata": {},
   "source": [
    "### Evaluate imitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2531231-394c-4fbf-92d9-243fd9dd4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import argmax\n",
    "\n",
    "def evaluate_imitation(model, N=500):\n",
    "    \"\"\"Measure accuracy based on unseen expert demonstration state-action pairs.\"\"\"\n",
    "    print(\"\\nevaluating imitation accuracy\\n\")\n",
    "    model.eval()\n",
    "    data_test = DataLoader(generate_data(N))\n",
    "    total_correct = 0\n",
    "    for batch in data_test:\n",
    "        # compute node scores\n",
    "        y = model(batch)\n",
    "        # softmax over node scores per graph, using batch indices\n",
    "        y = softmax(y, batch.batch)\n",
    "        # restack for loss calculation\n",
    "        pred = stacked_batch(y, batch.batch)\n",
    "        pred = argmax(pred, dim=1)\n",
    "        target = batch.action\n",
    "        total_correct += pred == target\n",
    "    print(f\"accuracy: {total_correct.item() / len(data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1897aef-dc6e-4306-ba23-51d944e82e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating imitation accuracy\n",
      "\n",
      "accuracy: 0.3215\n"
     ]
    }
   ],
   "source": [
    "evaluate_imitation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895bd144-8972-4f42-9c17-1385e74f13d9",
   "metadata": {},
   "source": [
    "### Evaluate scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7f05b-9379-4e89-9d93-b9e881af3515",
   "metadata": {},
   "source": [
    "Current definition of objective in `exact.py` is total sum of crossing times, including at exit points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2f61be9-2fd6-4adb-882c-08824aea8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import masked_select\n",
    "\n",
    "def evaluate_scheduling(model, N=100):\n",
    "    \"\"\"Evaluate average objective when executing the policy over full\n",
    "    unseen problem instances compared to average optimal objective.\"\"\"\n",
    "    print(\"\\nevaluating policy\\n\")\n",
    "    model.eval()\n",
    "    obj_opt = 0\n",
    "    obj_model = 0\n",
    "    for _ in range(N):\n",
    "        instance = generate_simple_instance()\n",
    "\n",
    "        # solve optimally\n",
    "        y, obj = solve(instance)\n",
    "        obj_opt += obj\n",
    "\n",
    "        # TEST objective definition\n",
    "        # _, actions, _ = collect_state_action_pairs(instance, y)\n",
    "\n",
    "        # execute learned heuristic\n",
    "        automaton = Automaton(instance)\n",
    "        while not automaton.done:\n",
    "            state = automaton.D\n",
    "            graph = from_networkx(state, group_node_attrs=['LB', 'done'])\n",
    "            # compute node scores\n",
    "            y = model(graph)\n",
    "            # mask valid actions (set to -inf)\n",
    "            y = y.masked_fill(~graph.action_mask.bool(), -torch.inf)\n",
    "            y = argmax(y)\n",
    "            action = valid_actions[y]\n",
    "            r, k, v = action\n",
    "\n",
    "            # transform to valid action\n",
    "            automaton.step(r, v)\n",
    "\n",
    "        # TEST objective definition\n",
    "        # for action in actions:\n",
    "        #     r, k, v = action\n",
    "        #     automaton.step(r, v)\n",
    "\n",
    "        # compute obj from automaton\n",
    "        obj_model += automaton.get_obj()\n",
    "\n",
    "    print(f\"obj_opt={obj_opt / N} vs obj_model={obj_model / N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45cd41aa-95e0-4da4-828e-41a6ed3e6c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating policy\n",
      "\n",
      "obj_opt=312.57050607140025 vs obj_model=322.8857129350818\n"
     ]
    }
   ],
   "source": [
    "evaluate_scheduling(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158508d-a345-4b14-8203-e4f840edb7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
